% !TEX root = laws.tex
\raggedbottom
\subsection{Related Work}

Verification and testing of software systems \cite{myers2011art} is an integral part of a software development lifecycle. Immediately after the implementation of the software, and before its deployment, it has to be verified and tested extensively enough to ensure that all the functional requirements have been properly met. A lot of methods have been developed over the course of time for verification and testing of software. Formal verification \cite{wang2004formal}, for example, is a popular method of program verification~(though testing still remains more prevalent). It is used to validate the correctness of a software module by modeling its behaviour based on a set of formal methods, which are mathematical models specifying the intended functional behaviour. Though there are a lot of formal methods used for this, the most common methods are the ones based on finite state machines \cite{chow1978testing}, Petri Nets, process algebra and timed automata \cite{clarke1996formal}. Prior to formal verification, a mathematical model employing a formal method is decided upon which is then followed by a specification phase where the behaviour of the system is modeled. Finally the actual program is verified against this behaviour specification which is called the verification phase.% In the late 90's, some optimisations were proposed to the otherwise conventional and inefficient exhaustive search methods \mnote{either improve or remove this line}.\cite{holzmann1995improvement}.

Since a software program is developed at module or class level and is integrated with other modules or classes along the development cycle, testing is done at unit level, integration level and system level \cite{myers2011art}, before the software is deployed. End-to-end testing \cite{tsai2001end} is also performed, usually after system testing~(sometimes it is seen as a kind of system testing as well), to validate correct flow spanning different components of the software in real world use cases. Unit tests target individual modules, methods or classes and have a small coverage compared to integration tests which aim towards checking the behaviour of modules when combined together. The two main approaches to unit testing are black box testing and white box testing. The former one focuses on designing test instances without looking inside the code or design, in other words, the black box testing 
is only focusing on the functionality of the unit under testing, while the white box testing approach is more inclined towards testing code coverage i.e. writing test instances which employ the different paths inside the code.

Though initially white box testing was considered as a method suitable for unit testing alone, recently it has emerged as a popular method for integration testing as well. Integration testing is usually done by one or a combination of the following approaches: 
\begin{enumerate}[\IEEEsetlabelwidth{Z}]
\item \textit{Big-Bang approach}.\\In this approach, all the components are integrated together at once and then tested. This method works well for comparatively smaller systems, but is not well suited for larger systems. One obvious disadvantage being that the testing can only begin after all the individual components have been built.
\item \textit{Top-Down approach}.\\As the name suggests, the modules at upper level are tested first and then we move down until we reach the lowest level modules which will be tested at the end. Since lower level modules might not be developed when the upper ones are being tested, stubs are used in place of such the modules. The stubs are trying to simulate behaviour of the modules not implemented yet.
\item \textit{Bottom-Up approach}.\\This approach is opposite to the top-down. Here the lower level modules are tested first and then we iteratively move upwards in the hierarchy until we reach the highest level module. Now as we are testing lower level modules first, stubs are used to simulate the behaviour of higher level modules which may not be implemented yet, if any sibling interaction is required. 
\item \textit{Sandwich approach}.\\ The Sandwich approach is a combination of the Bottom-Up and Top-Down approaches.
\end{enumerate}

Opposed to the conventional unit testing methods which do not take any input parameters, parameterized unit tests~\cite{tillmann2010parameterized} are generalized tests which have an encapsulated collection of test methods whose invocation and behaviour is controlled by a set of input parameters giving more flexibility and automation to unit testing as a whole.

The final full scale testing that a software product undergoes is called the system testing, which includes tests like security test, compatibility test, exceptions handling, scalability tests, stress tests and performance tests. 

In 2013, Visa performed an annual stress test (comes under system testing) to prepare their system VisaNet for the peak traffic of the upcoming holiday season. The test results showed that the system was able to handle 47,000 transactions per second which was around 56\% improvement from the previous year's capacity of the system. %[https://www.visa.com/blogarchives/us/2013/10/10/stress-test-prepares-visanet-for-the-most-wonderful-time-of-the-year/index.html].
Another recent work~\cite{baqer2016stressing} mentions a spam campaign, called \textit{"stress test"}, on the Bitcoin network [Bitcoin cite] caused the network's performance to degrade and essentially resulted in a Denial-of-Service attack, which is cyber-attack on a system where the attack makes the system's resources unavailable or degrades their intended quality to a point where it becomes difficult or sometimes impossible for the honest users to avail the resource. The intention behind this campaign was to expose the vulnerabilities of the network, particularly to spam attacks, and to therefore increase the present transaction verification rate of the network. The authors of the paper~\cite{baqer2016stressing} present an experimental analysis of the above mentioned "attack" by using $k$-means clustering along with some specific features to differentiate between spam and actual transactions. They report that around 23\% of the total transactions flowing on the network were indeed spams during the peak period of the attack. Since this number is a pretty significant number and potentially degrade the network by at least a quarter. As a consequence of this attack, a special type of transactions were observed, called $UTXO$-cleanup transactions, which were created by miners to combine spam transaction together, reducing the $UTXO$ set size, and hence reduce the impact of the attack on the network. 

% ignored text begins
\ignore{ Similar to this, another vulnerability in the Bitcoin system caused MtGox Bitcoin exchange to close in February 2014 [?https://www.businessinsider.in/Bitcoin-Just-Completely-Crashed-As-Major-Exchange-Says-Withdrawals-Remain-Halted/articleshow/30165462.cms]. The exchange announced that close to 850,000 bitcoins were stolen by an attacker who exploited the vulnerability that causes bitcoin transactions to be malleable. Let us denote a bitcoin transaction as the tuple $T = (M, sig$) where $M$ is the message content of transaction and $sig$ is a valid signature on $M$. If a transaction is non-malleable, then it is not viable to construct another transaction $T' = (M, sig')$ such that $sig'$ is also a valid signature on $M$, without the knowledge of the secret key. Due to the fact that in bitcoin a transaction is identified by its unique $id = \mathbb{H}(M, sig)$, where $\mathbb{H}$ is a hash function, and not just $id = \mathbb{H}(M)$ means that $T$ and $T'$ as mentioned above will be treated as different transactions since they will have different $id$, despite the fact that their transaction content is exactly same. The above malleability is possible due to the fact that signature schemes used in bitcoin can be malleable. The way this attack was used to steal money, as claimed by the exchange, is the following:
\begin{enumerate}[\IEEEsetlabelwidth{Z}]
\item A user begins by depositing a certain amount $a$ into exchange's account.
\item He then asks the exchange to transfer his money back to him.
\item The exchange issues a transaction $T$ to transfer $a$ bitcoins to the user's account.
\item The user constructs another transaction $T'$ by exploiting the malleability of transactions.
\item Suppose that somehow $T'$ gets included in the blockchain instead of $T$.
\item This ensures that the user gets $a$ bitcoins in his account. But after this, the user files a request for resending the money claiming that he didn't receive it.
\item To respond to this request, the exchange checks that no transaction with $id = id_T$ ($=\mathbb{H}(T)$) is present and reissues another transaction sending $a$ to the user. This way the user was able to receive double that coins that he were to receive without the vulnerability.
\end{enumerate}
A very intuitive solution [?https://eprint.iacr.org/2013/837.pdf] to this problem is to change bitcoin such that transactions are identified only with $M$ and not the input scripts (signatures). This would mean that even if a signature is forged, the new transaction will hash to the same $id$ as the previous transaction and would eliminate this issue. There is also another solution [?%https://fc15.ifca.ai/preproceedings/bitcoin/paper_9.pdf
] where malleability of bitcoin transaction is dealt-with specific to bitcoin contracts. }
% ignored text ends

These arguments make it pretty convincing that repeated testing of even the most carefully written and designed system is crucial to expose hidden vulnerabilities in the developed system which might miss the eye of the developers. Such tests are performed regularly on important system and help ensure their reliability, security and performance. But, if we talk about Bitcoin and other blockchain system, where the cost of errors can be humungous, then testing becomes the most important part of the software development lifecycle.

In this manuscript we focus on a different method of program testing, called property testing \cite{ron2001property}. This method is concerned with making approximate decisions on whether a function under test satisfies a property globally or not by using only a small number of random input domain elements. We argue that for testing an implementation on top of an abstract framework, like Scorex, this method is of particular interest, since we can split clearly and in a useful way work between the framework and the application. Concretely, properties an application should satisfy are provided before implementing it, and then an application developer just needs to write generators for random input domain elements the tests are using.   
\nocite{holzmann1995improvement}
\nocite{zaki2008formal}

%Some papers to use for references particular to property testing - http://www.wisdom.weizmann.ac.il/~oded/test.html.%
%Integration testing papers for references - https://www.researchgate.net/profile/Xiaoying_Bai/publication/221028427_End-To-End_Integration_Testing_Design/links/02e7e516cabf5c969d000000.pdf%
%Formal verification - http://www.cerc.utexas.edu/~jay/fv_surveys/zaki-AMS-survey-FULL.pdf%
%Formal verification - http://www.cerc.utexas.edu/~jay/fv_surveys/wang_fvsurvey_timed_systems_proc_ieee2004.pdf%
%Unit testing - https://link.springer.com/article/10.1007/s10664-006-5964-9%
%Integration testing - https://link.springer.com/chapter/10.1007/978-3-540-31862-0_18%
%http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.7961&rep=rep1&type=pdf%
%http://ieeexplore.ieee.org/document/1702519/%
%https://dl.acm.org/citation.cfm?id=1767341%



